{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random Forest Grid Search.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mulcahrj/DATA6545_Final/blob/main/Random_Forest_Grid_Search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vbpq0-TvMGNN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'https://raw.githubusercontent.com/mulcahrj/DATA6545_Final/main/selected_features_train.csv'\n",
        "features_train = pd.read_csv(path)\n",
        "\n",
        "path = 'https://raw.githubusercontent.com/mulcahrj/DATA6545_Final/main/selected_features_test.csv'\n",
        "features_test = pd.read_csv(path)"
      ],
      "metadata": {
        "id": "kf21HPAuMgiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frames = [features_test, features_train]\n",
        "\n",
        "data = pd.concat(frames)"
      ],
      "metadata": {
        "id": "hiblIADrMgu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split dataset into inputs and outputs\n",
        "X = data.values[:, :-1] \n",
        "y = data.values[:, -1] "
      ],
      "metadata": {
        "id": "KvB41leKMrtc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initiate the LR model with random hyperparameters\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=2019)"
      ],
      "metadata": {
        "id": "Dh7SONZhMtXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf.fit(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNb6D_K0MuJ2",
        "outputId": "38b345d0-68f0-4085-e5cc-caf07bfd5f1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(random_state=2019)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf.score(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypLsdOnLMvId",
        "outputId": "4b2ddcca-0d76-43f6-a6d5-97b1a7b6c611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999779283554417"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You will need the following dependencies for applying Cross-validation and evaluating the cross-validated score\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Build the k-fold cross-validator\n",
        "\n",
        "kfold = KFold(n_splits=3, random_state=2019, shuffle=True)"
      ],
      "metadata": {
        "id": "bLBhPgKyMw24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = cross_val_score(rf, X, y, cv=kfold, scoring='accuracy')\n",
        "print(result.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whFc4P82MyFy",
        "outputId": "e3e6711e-37b6-4707-d485-6454f8f8568c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8930187158261019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_estimators = [200,300,400]\n",
        "max_features = ['auto', 'sqrt', 'log2']\n",
        "max_depth = [4,6,8]\n",
        "criterion = ['gini', 'entropy']\n",
        "param_grid = dict(n_estimators=n_estimators, max_features=max_features, max_depth=max_depth, criterion = criterion)"
      ],
      "metadata": {
        "id": "LLDaQi9dM1zY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "np.random.seed(7)\n",
        "n_estimators1 = np.random.randint(200,300,400)\n",
        "max_features1 = ['auto', 'sqrt', 'log2']\n",
        "max_depth1 = np.random.randint(4,6,8)\n",
        "criterion1 = ['gini', 'entropy']\n",
        "param_grid1 = dict(n_estimators=n_estimators1, max_features=max_features1, max_depth=max_depth1, criterion = criterion1)"
      ],
      "metadata": {
        "id": "Ot8MPdcCNBQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "c9Zt6dwsNEaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=2019)\n",
        "grid = GridSearchCV(estimator=rf, param_grid=param_grid, cv = 3, n_jobs=-1)\n",
        "\n",
        "start_time = time.time()\n",
        "grid_result = grid.fit(X, y)\n",
        "# Summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
      ],
      "metadata": {
        "id": "Jzuka-upNCAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluation"
      ],
      "metadata": {
        "id": "YH53pANbQuKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import required package for data handling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# import required packages for splitting data\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# import required packages for evaluating models\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "# balance the data\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "metadata": {
        "id": "0c75pBszQtjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define features and target\n",
        "X = data.iloc[:,:-1].values\n",
        "y = data.iloc[:,-1].values"
      ],
      "metadata": {
        "id": "p5U-ODvPQy8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resampling and Balancing the data\n",
        "sm = SMOTE(random_state = 2021) \n",
        "X_res, Y_res = sm.fit_resample(X, y) "
      ],
      "metadata": {
        "id": "mBFN_86SQ1Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(criterion= 'entropy', max_depth= 4, max_features= 'auto', n_estimators= 200)"
      ],
      "metadata": {
        "id": "_lfXiW73Q2mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_eval(X, y, classifer = clf, k=10, scoring = 'f1'):\n",
        "  '''\n",
        "  return evaluation results (f1-score or ROC_AUC). \n",
        "  Built in k-fold evaluation.\n",
        "  INPUTS:\n",
        "  ----\n",
        "  - X: features; DataFrame or Numpy ndarray;\n",
        "  - y: target; DataFrame or Numpy ndarray;\n",
        "  - classifier: any sklearn (or its add-on) based classifier\n",
        "  - k: number of folds in cross validation\n",
        "  - scoring: evaluation metric ('f1' default or 'roc_auc')\n",
        "  OUTPUT:\n",
        "  ----\n",
        "  bias/variance score of selected metric.\n",
        "  '''\n",
        "  scores = []\n",
        "  for i in range(50):\n",
        "    #### generate random numbers to shuffle the data for training and test\n",
        "    np.random.seed(2021)\n",
        "    random_int = np.random.randint(0,3000)\n",
        "    #### create cross validation folds\n",
        "    kfold = model_selection.KFold(n_splits=k, random_state=random_int, shuffle=True)\n",
        "    #### record the score\n",
        "    score = model_selection.cross_val_score(clf, X=X, y=y, cv=kfold, scoring=scoring)\n",
        "    scores.append(score)\n",
        "  scores = np.array(scores)\n",
        "  #### we need to calculate the bias (average score) and viariance (std)\n",
        "  bias, variance = round(scores.mean(),4), round(scores.std(),4)\n",
        "  return(bias, variance)"
      ],
      "metadata": {
        "id": "hXUhe04YQ37T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting averaged f1_score from 10-fold CV (default)\n",
        "my_eval(X_res, Y_res, clf, 10)"
      ],
      "metadata": {
        "id": "UePGLp48Q5RM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting averaged ROC_AUC from 10-fold CV\n",
        "my_eval(X_res, Y_res, clf, 10, 'roc_auc')"
      ],
      "metadata": {
        "id": "WBVPIdL3Q6Zm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}